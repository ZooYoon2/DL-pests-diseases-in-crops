{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483892d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f2b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224, 224]\n",
    "vgg = VGG16(input_shape = image_size + [3], weights = 'imagenet', include_top =  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f6c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28960dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ST/trainData/Tomato\\\\Tomato_leafMold',\n",
       " 'D:/ST/trainData/Tomato\\\\Tomato_leafSpot',\n",
       " 'D:/ST/trainData/Tomato\\\\Tomato_nomal',\n",
       " 'D:/ST/trainData/Tomato\\\\Tomato_trifolii',\n",
       " 'D:/ST/trainData/Tomato\\\\Tomato_yellowLeafCurlVirus']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "folders = glob('D:/ST/trainData/Tomato/*')\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04b386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlayer = Flatten()(vgg.output)\n",
    "outlayer = Dense(4096, activation='relu',name='fc1')(outlayer)\n",
    "outlayer = Dropout(0.5)(outlayer)\n",
    "outlayer = Dense(4096, activation='relu',name='fc2')(outlayer)\n",
    "prediction = Dense(len(folders), activation = 'softmax')(outlayer)\n",
    "model = Model(inputs = vgg.input, outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0da946a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,281,029\n",
      "Trainable params: 119,566,341\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f656e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d43d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aaa67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 전처리 무작위 변형\n",
    "train_data_gen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2 \\\n",
    "                                    , zoom_range = 0.2, horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84cf6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1668 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_data_gen.flow_from_directory('D:/ST/trainData/Tomato/' \\\n",
    "                                               , target_size = (224,224) \\\n",
    "                                               , shuffle = True \\\n",
    "                                               , batch_size = 16, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15aa4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0dd807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 409 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_data_gen.flow_from_directory('D:/ST/trainData/Tomato_val/' \\\n",
    "                                             , target_size = (224,224) \\\n",
    "                                             , shuffle = True \\\n",
    "                                             , batch_size = 16, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bdaa41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER-PC\\AppData\\Local\\Temp\\ipykernel_14708\\1667835563.py:14: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  mod = model.fit_generator(train_set,epochs=10, steps_per_epoch=len(train_set) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 2.8379 - accuracy: 0.5845\n",
      "Epoch 00001: val_loss improved from inf to 1.53134, saving model to Tomato_model_checkpoint.h5\n",
      "105/105 [==============================] - 547s 5s/step - loss: 2.8379 - accuracy: 0.5845 - val_loss: 1.5313 - val_accuracy: 0.4010\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.7916 - accuracy: 0.7002\n",
      "Epoch 00002: val_loss improved from 1.53134 to 1.23767, saving model to Tomato_model_checkpoint.h5\n",
      "105/105 [==============================] - 484s 5s/step - loss: 0.7916 - accuracy: 0.7002 - val_loss: 1.2377 - val_accuracy: 0.4645\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.7128 - accuracy: 0.7218\n",
      "Epoch 00003: val_loss did not improve from 1.23767\n",
      "105/105 [==============================] - 524s 5s/step - loss: 0.7128 - accuracy: 0.7218 - val_loss: 1.5036 - val_accuracy: 0.5086\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.7446\n",
      "Epoch 00004: val_loss improved from 1.23767 to 1.11041, saving model to Tomato_model_checkpoint.h5\n",
      "105/105 [==============================] - 503s 5s/step - loss: 0.6746 - accuracy: 0.7446 - val_loss: 1.1104 - val_accuracy: 0.4914\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.6012 - accuracy: 0.7614\n",
      "Epoch 00005: val_loss did not improve from 1.11041\n",
      "105/105 [==============================] - 524s 5s/step - loss: 0.6012 - accuracy: 0.7614 - val_loss: 1.3373 - val_accuracy: 0.4572\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.7356\n",
      "Epoch 00006: val_loss improved from 1.11041 to 1.03982, saving model to Tomato_model_checkpoint.h5\n",
      "105/105 [==============================] - 525s 5s/step - loss: 0.6996 - accuracy: 0.7356 - val_loss: 1.0398 - val_accuracy: 0.6039\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.7704\n",
      "Epoch 00007: val_loss did not improve from 1.03982\n",
      "105/105 [==============================] - 532s 5s/step - loss: 0.6071 - accuracy: 0.7704 - val_loss: 1.2078 - val_accuracy: 0.5012\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.6001 - accuracy: 0.7746\n",
      "Epoch 00008: val_loss did not improve from 1.03982\n",
      "105/105 [==============================] - 522s 5s/step - loss: 0.6001 - accuracy: 0.7746 - val_loss: 1.0759 - val_accuracy: 0.4963\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.7878\n",
      "Epoch 00009: val_loss did not improve from 1.03982\n",
      "105/105 [==============================] - 541s 5s/step - loss: 0.5448 - accuracy: 0.7878 - val_loss: 1.3586 - val_accuracy: 0.5257\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.7794\n",
      "Epoch 00010: val_loss did not improve from 1.03982\n",
      "105/105 [==============================] - 523s 5s/step - loss: 0.5837 - accuracy: 0.7794 - val_loss: 1.1270 - val_accuracy: 0.5281\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
    "\n",
    "path_checkpoint = \"Tomato_model_checkpoint.h5\"\n",
    "es_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "modelckpt_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    mod = model.fit_generator(train_set,epochs=10, steps_per_epoch=len(train_set) \\\n",
    "                    ,callbacks=[es_callback, modelckpt_callback] \\\n",
    "                    ,validation_data=test_set, validation_steps=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d504b0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 7.0346 - accuracy: 0.5108 \n",
      "Epoch 00001: val_loss improved from inf to 1.74667, saving model to Tomato_model_checkpoint.h5\n",
      "53/53 [==============================] - 689s 13s/step - loss: 7.0346 - accuracy: 0.5108 - val_loss: 1.7467 - val_accuracy: 0.4401\n",
      "Epoch 2/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.7841 - accuracy: 0.6829\n",
      "Epoch 00002: val_loss improved from 1.74667 to 1.33623, saving model to Tomato_model_checkpoint.h5\n",
      "53/53 [==============================] - 449s 9s/step - loss: 0.7841 - accuracy: 0.6829 - val_loss: 1.3362 - val_accuracy: 0.4621\n",
      "Epoch 3/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6809 - accuracy: 0.7338\n",
      "Epoch 00003: val_loss improved from 1.33623 to 1.14839, saving model to Tomato_model_checkpoint.h5\n",
      "53/53 [==============================] - 471s 9s/step - loss: 0.6809 - accuracy: 0.7338 - val_loss: 1.1484 - val_accuracy: 0.4866\n",
      "Epoch 4/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6472 - accuracy: 0.7350\n",
      "Epoch 00004: val_loss improved from 1.14839 to 1.09397, saving model to Tomato_model_checkpoint.h5\n",
      "53/53 [==============================] - 486s 9s/step - loss: 0.6472 - accuracy: 0.7350 - val_loss: 1.0940 - val_accuracy: 0.5061\n",
      "Epoch 5/5\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5989 - accuracy: 0.7626\n",
      "Epoch 00005: val_loss did not improve from 1.09397\n",
      "53/53 [==============================] - 494s 9s/step - loss: 0.5989 - accuracy: 0.7626 - val_loss: 1.3707 - val_accuracy: 0.4719\n"
     ]
    }
   ],
   "source": [
    "\"\"\"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
    "\n",
    "path_checkpoint = \"Tomato_model_checkpoint.h5\"\n",
    "es_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "modelckpt_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    mod = model.fit(train_set,epochs=10 \\\n",
    "                    ,callbacks=[es_callback, modelckpt_callback] \\\n",
    "                    ,validation_data=test_set)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d52edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model_5class_test2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Model_5class_test2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
